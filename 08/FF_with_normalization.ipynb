{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784       # The image size = 28 x 28 = 784\n",
    "hidden_size = 500      # The number of nodes at the hidden layer\n",
    "num_classes = 10       # The number of output classes. In this case, from 0 to 9\n",
    "num_epochs = 5         # The number of times entire dataset is trained\n",
    "batch_size = 100       # The size of input data took for one iteration\n",
    "learning_rate = 0.001  # The speed of convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])\n",
    "train_dataset = dsets.MNIST(root='./data',\n",
    "                           train=True,\n",
    "                           transform=transform,\n",
    "                           download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data',\n",
    "                           train=False,\n",
    "                           transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.3860, -0.1951,\n",
       "           -0.1951, -0.1951,  1.1795,  1.3068,  1.8032, -0.0933,  1.6887,\n",
       "            2.8215,  2.7197,  1.1923, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.0424,  0.0340,  0.7722,  1.5359,  1.7396,  2.7960,\n",
       "            2.7960,  2.7960,  2.7960,  2.7960,  2.4396,  1.7650,  2.7960,\n",
       "            2.6560,  2.0578,  0.3904, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "            0.1995,  2.6051,  2.7960,  2.7960,  2.7960,  2.7960,  2.7960,\n",
       "            2.7960,  2.7960,  2.7960,  2.7706,  0.7595,  0.6195,  0.6195,\n",
       "            0.2886,  0.0722, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.1951,  2.3633,  2.7960,  2.7960,  2.7960,  2.7960,  2.7960,\n",
       "            2.0960,  1.8923,  2.7197,  2.6433, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242,  0.5940,  1.5614,  0.9377,  2.7960,  2.7960,  2.1851,\n",
       "           -0.2842, -0.4242,  0.1231,  1.5359, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.2460, -0.4115,  1.5359,  2.7960,  0.7213,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242,  1.3450,  2.7960,  1.9942,\n",
       "           -0.3988, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.2842,  1.9942,  2.7960,\n",
       "            0.4668, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.0213,  2.6433,\n",
       "            2.4396,  1.6123,  0.9504, -0.4115, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.6068,\n",
       "            2.6306,  2.7960,  2.7960,  1.0904, -0.1060, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "            0.1486,  1.9432,  2.7960,  2.7960,  1.4850, -0.0806, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.2206,  0.7595,  2.7833,  2.7960,  1.9560, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242,  2.7451,  2.7960,  2.7451,  0.3904,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "            0.1613,  1.2305,  1.9051,  2.7960,  2.7960,  2.2105, -0.3988,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.0722,  1.4596,\n",
       "            2.4906,  2.7960,  2.7960,  2.7960,  2.7578,  1.8923, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.1187,  1.0268,  2.3887,  2.7960,\n",
       "            2.7960,  2.7960,  2.7960,  2.1342,  0.5686, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.1315,  0.4159,  2.2869,  2.7960,  2.7960,  2.7960,\n",
       "            2.7960,  2.0960,  0.6068, -0.3988, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.1951,\n",
       "            1.7523,  2.3633,  2.7960,  2.7960,  2.7960,  2.7960,  2.0578,\n",
       "            0.5940, -0.3097, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242,  0.2758,  1.7650,  2.4524,\n",
       "            2.7960,  2.7960,  2.7960,  2.7960,  2.6815,  1.2686, -0.2842,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242,  1.3068,  2.7960,  2.7960,\n",
       "            2.7960,  2.2742,  1.2941,  1.2559, -0.2206, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242]]]),\n",
       " tensor(5))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shuffle the loading process of train_dataset to make the learning process independent of data orderness, but the order of test_loader remains to examine whether we can handle unspecified bias order of inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedforward Neural Network Model Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(Net, self).__init__()                    # Inherited from the parent class nn.Module\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)  # 1st Full-Connected Layer: 784 (input data) -> 500 (hidden node)\n",
    "        self.relu = nn.ReLU()                          # Non-Linear ReLU Layer: max(0,x)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes) # 2nd Full-Connected Layer: 500 (hidden node) -> 10 (output class)\n",
    "    \n",
    "    def forward(self, x):                              # Forward pass: stacking each layer together\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the FNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(input_size, hidden_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0077, -0.0129, -0.0203,  ..., -0.0071,  0.0048, -0.0113],\n",
      "        [ 0.0221,  0.0278, -0.0158,  ..., -0.0030, -0.0351,  0.0140],\n",
      "        [-0.0031, -0.0132, -0.0318,  ...,  0.0301,  0.0068,  0.0027],\n",
      "        ...,\n",
      "        [-0.0138, -0.0271,  0.0112,  ...,  0.0178, -0.0179, -0.0045],\n",
      "        [ 0.0075, -0.0049, -0.0309,  ..., -0.0153, -0.0017,  0.0258],\n",
      "        [-0.0199, -0.0189,  0.0356,  ...,  0.0145, -0.0321,  0.0105]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0197,  0.0056,  0.0133,  0.0271, -0.0103,  0.0226,  0.0043,  0.0167,\n",
      "         0.0245, -0.0119,  0.0138, -0.0346,  0.0303, -0.0024,  0.0020,  0.0345,\n",
      "         0.0302, -0.0020, -0.0247,  0.0289,  0.0246,  0.0018,  0.0145, -0.0038,\n",
      "        -0.0336, -0.0269,  0.0186,  0.0357, -0.0038,  0.0312, -0.0349,  0.0294,\n",
      "         0.0194,  0.0242, -0.0019, -0.0251, -0.0331,  0.0058,  0.0257, -0.0345,\n",
      "        -0.0111, -0.0028, -0.0177, -0.0305,  0.0335,  0.0085,  0.0033,  0.0220,\n",
      "         0.0290,  0.0353, -0.0191,  0.0158, -0.0304,  0.0334, -0.0184,  0.0216,\n",
      "        -0.0195, -0.0072,  0.0323,  0.0287,  0.0107, -0.0029, -0.0016, -0.0038,\n",
      "         0.0147, -0.0296, -0.0194,  0.0061,  0.0309, -0.0073, -0.0110, -0.0211,\n",
      "         0.0083, -0.0039, -0.0309,  0.0310, -0.0289,  0.0033, -0.0310, -0.0046,\n",
      "         0.0040, -0.0355, -0.0284,  0.0044, -0.0029, -0.0173,  0.0079,  0.0283,\n",
      "         0.0064,  0.0072,  0.0151, -0.0257, -0.0079,  0.0172, -0.0188,  0.0034,\n",
      "         0.0226,  0.0000, -0.0338, -0.0236,  0.0297,  0.0274, -0.0092, -0.0145,\n",
      "        -0.0250, -0.0240,  0.0312, -0.0257, -0.0043,  0.0182, -0.0357, -0.0274,\n",
      "        -0.0185, -0.0141,  0.0149, -0.0160, -0.0212, -0.0031, -0.0326, -0.0326,\n",
      "         0.0076, -0.0249,  0.0328, -0.0021, -0.0025,  0.0252, -0.0094, -0.0158,\n",
      "         0.0265, -0.0348, -0.0132,  0.0190, -0.0057, -0.0153, -0.0217, -0.0251,\n",
      "         0.0272,  0.0253, -0.0226,  0.0293, -0.0014,  0.0280, -0.0074,  0.0096,\n",
      "        -0.0135,  0.0168,  0.0053, -0.0090, -0.0251,  0.0108,  0.0282, -0.0050,\n",
      "         0.0098, -0.0277,  0.0274, -0.0066,  0.0183,  0.0056,  0.0276, -0.0080,\n",
      "        -0.0004,  0.0139,  0.0344, -0.0211, -0.0240, -0.0142,  0.0048,  0.0248,\n",
      "        -0.0267,  0.0179, -0.0198,  0.0269,  0.0120, -0.0336, -0.0050, -0.0071,\n",
      "        -0.0050, -0.0015, -0.0286, -0.0330, -0.0222, -0.0301,  0.0271, -0.0002,\n",
      "        -0.0098,  0.0121,  0.0081, -0.0020,  0.0236,  0.0100,  0.0101,  0.0264,\n",
      "        -0.0349, -0.0064, -0.0148, -0.0244, -0.0001, -0.0209, -0.0032,  0.0072,\n",
      "        -0.0220, -0.0000, -0.0177, -0.0149, -0.0295,  0.0057,  0.0180, -0.0022,\n",
      "        -0.0176, -0.0014,  0.0014, -0.0288, -0.0136, -0.0238,  0.0284, -0.0252,\n",
      "         0.0142, -0.0104, -0.0169,  0.0169,  0.0203,  0.0242, -0.0274,  0.0087,\n",
      "         0.0071, -0.0354, -0.0106,  0.0178, -0.0070,  0.0104,  0.0252, -0.0194,\n",
      "        -0.0047, -0.0220,  0.0188, -0.0060, -0.0006,  0.0284, -0.0121, -0.0155,\n",
      "         0.0228, -0.0204, -0.0326, -0.0278, -0.0228, -0.0205,  0.0259, -0.0350,\n",
      "         0.0332, -0.0156, -0.0089,  0.0266,  0.0116,  0.0089, -0.0079,  0.0119,\n",
      "        -0.0067,  0.0179,  0.0305, -0.0331,  0.0048,  0.0189,  0.0260, -0.0196,\n",
      "        -0.0225,  0.0206, -0.0191, -0.0260, -0.0163, -0.0236, -0.0280,  0.0076,\n",
      "         0.0038, -0.0291, -0.0040,  0.0149,  0.0075,  0.0241, -0.0081, -0.0136,\n",
      "         0.0106,  0.0086, -0.0297,  0.0025,  0.0273,  0.0325,  0.0049,  0.0111,\n",
      "         0.0014,  0.0110, -0.0266, -0.0100,  0.0048,  0.0239, -0.0237,  0.0011,\n",
      "         0.0222,  0.0253,  0.0122, -0.0350,  0.0186,  0.0223,  0.0118, -0.0276,\n",
      "         0.0346, -0.0258,  0.0276,  0.0313, -0.0180, -0.0323,  0.0169,  0.0304,\n",
      "        -0.0110,  0.0062,  0.0155, -0.0048,  0.0290, -0.0086,  0.0341, -0.0056,\n",
      "        -0.0109, -0.0176,  0.0199, -0.0284, -0.0304, -0.0311,  0.0343,  0.0036,\n",
      "         0.0253,  0.0177,  0.0332,  0.0106, -0.0090, -0.0347,  0.0153,  0.0342,\n",
      "         0.0021,  0.0244, -0.0041,  0.0311, -0.0204,  0.0174, -0.0344, -0.0040,\n",
      "        -0.0126,  0.0230, -0.0224, -0.0088, -0.0073, -0.0072,  0.0307,  0.0028,\n",
      "         0.0208,  0.0327,  0.0141, -0.0327,  0.0211,  0.0292,  0.0105,  0.0193,\n",
      "        -0.0190, -0.0081, -0.0100,  0.0224, -0.0143, -0.0164, -0.0337, -0.0101,\n",
      "        -0.0006,  0.0108,  0.0208, -0.0143,  0.0184, -0.0100, -0.0079, -0.0175,\n",
      "         0.0257, -0.0079,  0.0005,  0.0068, -0.0288,  0.0159, -0.0023, -0.0139,\n",
      "         0.0085, -0.0349,  0.0063,  0.0353, -0.0144,  0.0326,  0.0073, -0.0071,\n",
      "        -0.0017, -0.0113, -0.0308, -0.0255,  0.0168, -0.0123, -0.0145, -0.0287,\n",
      "         0.0341, -0.0009, -0.0033,  0.0091, -0.0089,  0.0195, -0.0110, -0.0087,\n",
      "        -0.0106,  0.0073,  0.0013, -0.0003,  0.0200, -0.0133, -0.0140, -0.0283,\n",
      "        -0.0143, -0.0068, -0.0284, -0.0125,  0.0283, -0.0221, -0.0037,  0.0261,\n",
      "         0.0119,  0.0132,  0.0308, -0.0114,  0.0192, -0.0120,  0.0195,  0.0333,\n",
      "        -0.0229,  0.0045,  0.0230, -0.0127,  0.0028, -0.0292, -0.0092,  0.0162,\n",
      "         0.0115,  0.0229,  0.0143, -0.0024, -0.0192,  0.0141, -0.0296,  0.0012,\n",
      "         0.0153,  0.0114, -0.0100,  0.0010, -0.0096,  0.0187, -0.0129, -0.0351,\n",
      "        -0.0236, -0.0287, -0.0264,  0.0144, -0.0303, -0.0319, -0.0002,  0.0151,\n",
      "         0.0175,  0.0181, -0.0307, -0.0087, -0.0055, -0.0004,  0.0309, -0.0301,\n",
      "        -0.0003,  0.0241,  0.0201, -0.0187, -0.0280,  0.0040,  0.0090,  0.0133,\n",
      "        -0.0282, -0.0045, -0.0160,  0.0269, -0.0084,  0.0057,  0.0078,  0.0012,\n",
      "         0.0342,  0.0140, -0.0156, -0.0127, -0.0047,  0.0034, -0.0071, -0.0110,\n",
      "         0.0037,  0.0173,  0.0328,  0.0032], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0271,  0.0284, -0.0141,  ..., -0.0103, -0.0400,  0.0150],\n",
      "        [-0.0226, -0.0088,  0.0014,  ..., -0.0299,  0.0344, -0.0305],\n",
      "        [ 0.0343,  0.0123,  0.0202,  ..., -0.0394, -0.0212,  0.0013],\n",
      "        ...,\n",
      "        [ 0.0067,  0.0027,  0.0411,  ..., -0.0259, -0.0367,  0.0003],\n",
      "        [ 0.0151, -0.0433,  0.0150,  ..., -0.0145, -0.0309,  0.0167],\n",
      "        [-0.0281, -0.0175,  0.0228,  ..., -0.0294,  0.0272, -0.0202]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0310, -0.0071, -0.0242,  0.0170, -0.0159, -0.0210,  0.0166, -0.0075,\n",
      "        -0.0367, -0.0234], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "a=net.parameters()\n",
    "for i in a:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose the Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0077, -0.0129, -0.0203,  ..., -0.0071,  0.0048, -0.0113],\n",
      "        [ 0.0221,  0.0278, -0.0158,  ..., -0.0030, -0.0351,  0.0140],\n",
      "        [-0.0031, -0.0132, -0.0318,  ...,  0.0301,  0.0068,  0.0027],\n",
      "        ...,\n",
      "        [-0.0138, -0.0271,  0.0112,  ...,  0.0178, -0.0179, -0.0045],\n",
      "        [ 0.0075, -0.0049, -0.0309,  ..., -0.0153, -0.0017,  0.0258],\n",
      "        [-0.0199, -0.0189,  0.0356,  ...,  0.0145, -0.0321,  0.0105]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0197,  0.0056,  0.0133,  0.0271, -0.0103,  0.0226,  0.0043,  0.0167,\n",
      "         0.0245, -0.0119,  0.0138, -0.0346,  0.0303, -0.0024,  0.0020,  0.0345,\n",
      "         0.0302, -0.0020, -0.0247,  0.0289,  0.0246,  0.0018,  0.0145, -0.0038,\n",
      "        -0.0336, -0.0269,  0.0186,  0.0357, -0.0038,  0.0312, -0.0349,  0.0294,\n",
      "         0.0194,  0.0242, -0.0019, -0.0251, -0.0331,  0.0058,  0.0257, -0.0345,\n",
      "        -0.0111, -0.0028, -0.0177, -0.0305,  0.0335,  0.0085,  0.0033,  0.0220,\n",
      "         0.0290,  0.0353, -0.0191,  0.0158, -0.0304,  0.0334, -0.0184,  0.0216,\n",
      "        -0.0195, -0.0072,  0.0323,  0.0287,  0.0107, -0.0029, -0.0016, -0.0038,\n",
      "         0.0147, -0.0296, -0.0194,  0.0061,  0.0309, -0.0073, -0.0110, -0.0211,\n",
      "         0.0083, -0.0039, -0.0309,  0.0310, -0.0289,  0.0033, -0.0310, -0.0046,\n",
      "         0.0040, -0.0355, -0.0284,  0.0044, -0.0029, -0.0173,  0.0079,  0.0283,\n",
      "         0.0064,  0.0072,  0.0151, -0.0257, -0.0079,  0.0172, -0.0188,  0.0034,\n",
      "         0.0226,  0.0000, -0.0338, -0.0236,  0.0297,  0.0274, -0.0092, -0.0145,\n",
      "        -0.0250, -0.0240,  0.0312, -0.0257, -0.0043,  0.0182, -0.0357, -0.0274,\n",
      "        -0.0185, -0.0141,  0.0149, -0.0160, -0.0212, -0.0031, -0.0326, -0.0326,\n",
      "         0.0076, -0.0249,  0.0328, -0.0021, -0.0025,  0.0252, -0.0094, -0.0158,\n",
      "         0.0265, -0.0348, -0.0132,  0.0190, -0.0057, -0.0153, -0.0217, -0.0251,\n",
      "         0.0272,  0.0253, -0.0226,  0.0293, -0.0014,  0.0280, -0.0074,  0.0096,\n",
      "        -0.0135,  0.0168,  0.0053, -0.0090, -0.0251,  0.0108,  0.0282, -0.0050,\n",
      "         0.0098, -0.0277,  0.0274, -0.0066,  0.0183,  0.0056,  0.0276, -0.0080,\n",
      "        -0.0004,  0.0139,  0.0344, -0.0211, -0.0240, -0.0142,  0.0048,  0.0248,\n",
      "        -0.0267,  0.0179, -0.0198,  0.0269,  0.0120, -0.0336, -0.0050, -0.0071,\n",
      "        -0.0050, -0.0015, -0.0286, -0.0330, -0.0222, -0.0301,  0.0271, -0.0002,\n",
      "        -0.0098,  0.0121,  0.0081, -0.0020,  0.0236,  0.0100,  0.0101,  0.0264,\n",
      "        -0.0349, -0.0064, -0.0148, -0.0244, -0.0001, -0.0209, -0.0032,  0.0072,\n",
      "        -0.0220, -0.0000, -0.0177, -0.0149, -0.0295,  0.0057,  0.0180, -0.0022,\n",
      "        -0.0176, -0.0014,  0.0014, -0.0288, -0.0136, -0.0238,  0.0284, -0.0252,\n",
      "         0.0142, -0.0104, -0.0169,  0.0169,  0.0203,  0.0242, -0.0274,  0.0087,\n",
      "         0.0071, -0.0354, -0.0106,  0.0178, -0.0070,  0.0104,  0.0252, -0.0194,\n",
      "        -0.0047, -0.0220,  0.0188, -0.0060, -0.0006,  0.0284, -0.0121, -0.0155,\n",
      "         0.0228, -0.0204, -0.0326, -0.0278, -0.0228, -0.0205,  0.0259, -0.0350,\n",
      "         0.0332, -0.0156, -0.0089,  0.0266,  0.0116,  0.0089, -0.0079,  0.0119,\n",
      "        -0.0067,  0.0179,  0.0305, -0.0331,  0.0048,  0.0189,  0.0260, -0.0196,\n",
      "        -0.0225,  0.0206, -0.0191, -0.0260, -0.0163, -0.0236, -0.0280,  0.0076,\n",
      "         0.0038, -0.0291, -0.0040,  0.0149,  0.0075,  0.0241, -0.0081, -0.0136,\n",
      "         0.0106,  0.0086, -0.0297,  0.0025,  0.0273,  0.0325,  0.0049,  0.0111,\n",
      "         0.0014,  0.0110, -0.0266, -0.0100,  0.0048,  0.0239, -0.0237,  0.0011,\n",
      "         0.0222,  0.0253,  0.0122, -0.0350,  0.0186,  0.0223,  0.0118, -0.0276,\n",
      "         0.0346, -0.0258,  0.0276,  0.0313, -0.0180, -0.0323,  0.0169,  0.0304,\n",
      "        -0.0110,  0.0062,  0.0155, -0.0048,  0.0290, -0.0086,  0.0341, -0.0056,\n",
      "        -0.0109, -0.0176,  0.0199, -0.0284, -0.0304, -0.0311,  0.0343,  0.0036,\n",
      "         0.0253,  0.0177,  0.0332,  0.0106, -0.0090, -0.0347,  0.0153,  0.0342,\n",
      "         0.0021,  0.0244, -0.0041,  0.0311, -0.0204,  0.0174, -0.0344, -0.0040,\n",
      "        -0.0126,  0.0230, -0.0224, -0.0088, -0.0073, -0.0072,  0.0307,  0.0028,\n",
      "         0.0208,  0.0327,  0.0141, -0.0327,  0.0211,  0.0292,  0.0105,  0.0193,\n",
      "        -0.0190, -0.0081, -0.0100,  0.0224, -0.0143, -0.0164, -0.0337, -0.0101,\n",
      "        -0.0006,  0.0108,  0.0208, -0.0143,  0.0184, -0.0100, -0.0079, -0.0175,\n",
      "         0.0257, -0.0079,  0.0005,  0.0068, -0.0288,  0.0159, -0.0023, -0.0139,\n",
      "         0.0085, -0.0349,  0.0063,  0.0353, -0.0144,  0.0326,  0.0073, -0.0071,\n",
      "        -0.0017, -0.0113, -0.0308, -0.0255,  0.0168, -0.0123, -0.0145, -0.0287,\n",
      "         0.0341, -0.0009, -0.0033,  0.0091, -0.0089,  0.0195, -0.0110, -0.0087,\n",
      "        -0.0106,  0.0073,  0.0013, -0.0003,  0.0200, -0.0133, -0.0140, -0.0283,\n",
      "        -0.0143, -0.0068, -0.0284, -0.0125,  0.0283, -0.0221, -0.0037,  0.0261,\n",
      "         0.0119,  0.0132,  0.0308, -0.0114,  0.0192, -0.0120,  0.0195,  0.0333,\n",
      "        -0.0229,  0.0045,  0.0230, -0.0127,  0.0028, -0.0292, -0.0092,  0.0162,\n",
      "         0.0115,  0.0229,  0.0143, -0.0024, -0.0192,  0.0141, -0.0296,  0.0012,\n",
      "         0.0153,  0.0114, -0.0100,  0.0010, -0.0096,  0.0187, -0.0129, -0.0351,\n",
      "        -0.0236, -0.0287, -0.0264,  0.0144, -0.0303, -0.0319, -0.0002,  0.0151,\n",
      "         0.0175,  0.0181, -0.0307, -0.0087, -0.0055, -0.0004,  0.0309, -0.0301,\n",
      "        -0.0003,  0.0241,  0.0201, -0.0187, -0.0280,  0.0040,  0.0090,  0.0133,\n",
      "        -0.0282, -0.0045, -0.0160,  0.0269, -0.0084,  0.0057,  0.0078,  0.0012,\n",
      "         0.0342,  0.0140, -0.0156, -0.0127, -0.0047,  0.0034, -0.0071, -0.0110,\n",
      "         0.0037,  0.0173,  0.0328,  0.0032], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0271,  0.0284, -0.0141,  ..., -0.0103, -0.0400,  0.0150],\n",
      "        [-0.0226, -0.0088,  0.0014,  ..., -0.0299,  0.0344, -0.0305],\n",
      "        [ 0.0343,  0.0123,  0.0202,  ..., -0.0394, -0.0212,  0.0013],\n",
      "        ...,\n",
      "        [ 0.0067,  0.0027,  0.0411,  ..., -0.0259, -0.0367,  0.0003],\n",
      "        [ 0.0151, -0.0433,  0.0150,  ..., -0.0145, -0.0309,  0.0167],\n",
      "        [-0.0281, -0.0175,  0.0228,  ..., -0.0294,  0.0272, -0.0202]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0310, -0.0071, -0.0242,  0.0170, -0.0159, -0.0210,  0.0166, -0.0075,\n",
      "        -0.0367, -0.0234], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i in net.parameters():\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the FNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joshhu/anaconda3/envs/pytorch/lib/python3.6/site-packages/ipykernel/__main__.py:10: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/home/joshhu/anaconda3/envs/pytorch/lib/python3.6/site-packages/ipykernel/__main__.py:16: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 0.0364\n",
      "Epoch [1/5], Step [200/600], Loss: 0.0502\n",
      "Epoch [1/5], Step [300/600], Loss: 0.1098\n",
      "Epoch [1/5], Step [400/600], Loss: 0.0170\n",
      "Epoch [1/5], Step [500/600], Loss: 0.0110\n",
      "Epoch [1/5], Step [600/600], Loss: 0.0102\n",
      "Epoch [2/5], Step [100/600], Loss: 0.0193\n",
      "Epoch [2/5], Step [200/600], Loss: 0.0629\n",
      "Epoch [2/5], Step [300/600], Loss: 0.0188\n",
      "Epoch [2/5], Step [400/600], Loss: 0.1702\n",
      "Epoch [2/5], Step [500/600], Loss: 0.0034\n",
      "Epoch [2/5], Step [600/600], Loss: 0.0045\n",
      "Epoch [3/5], Step [100/600], Loss: 0.0423\n",
      "Epoch [3/5], Step [200/600], Loss: 0.0601\n",
      "Epoch [3/5], Step [300/600], Loss: 0.0283\n",
      "Epoch [3/5], Step [400/600], Loss: 0.0081\n",
      "Epoch [3/5], Step [500/600], Loss: 0.0072\n",
      "Epoch [3/5], Step [600/600], Loss: 0.0010\n",
      "Epoch [4/5], Step [100/600], Loss: 0.0026\n",
      "Epoch [4/5], Step [200/600], Loss: 0.0126\n",
      "Epoch [4/5], Step [300/600], Loss: 0.0226\n",
      "Epoch [4/5], Step [400/600], Loss: 0.0062\n",
      "Epoch [4/5], Step [500/600], Loss: 0.0244\n",
      "Epoch [4/5], Step [600/600], Loss: 0.0182\n",
      "Epoch [5/5], Step [100/600], Loss: 0.0017\n",
      "Epoch [5/5], Step [200/600], Loss: 0.0073\n",
      "Epoch [5/5], Step [300/600], Loss: 0.0014\n",
      "Epoch [5/5], Step [400/600], Loss: 0.0025\n",
      "Epoch [5/5], Step [500/600], Loss: 0.0140\n",
      "Epoch [5/5], Step [600/600], Loss: 0.0166\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):   # Load a batch of images with its (index, data, class)\n",
    "        images = torch.FloatTensor(images.view(-1, 28*28))         # Convert torch tensor to Variable: change image from a vector of size 784 to a matrix of 28 x 28\n",
    "        labels = torch.LongTensor(labels)\n",
    "        \n",
    "        optimizer.zero_grad()                             # Intialize the hidden weight to all zeros\n",
    "        outputs = net(images)                             # Forward pass: compute the output class given a image\n",
    "        loss = criterion(outputs, labels)                 # Compute the loss: difference between the output class and the pre-given label\n",
    "        losses.append(loss.data[0])\n",
    "        loss.backward()                                   # Backward pass: compute the weight\n",
    "        optimizer.step()                                  # Optimizer: update the weights of hidden nodes\n",
    "        \n",
    "        if (i+1) % 100 == 0:                              # Logging\n",
    "            print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n",
    "                 %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the FNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to training the nerual network, we also need to load batches of test images and collect the outputs. The differences are that:\n",
    "(1) No loss & weights calculation\n",
    "(2) No wights update\n",
    "(3) Has correct prediction calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10K test images: 98 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images = torch.FloatTensor(images.view(-1, 28*28))\n",
    "    outputs = net(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)  # Choose the best class from the output: The class with the best score\n",
    "    total += labels.size(0)                    # Increment the total count\n",
    "    correct += (predicted == labels).sum()     # Increment the correct count\n",
    "    \n",
    "print('Accuracy of the network on the 10K test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the trained FNN Model for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(net.state_dict(), 'fnn_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7efe4a736390>]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
